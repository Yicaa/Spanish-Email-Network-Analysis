---
title: "Spanish Email Network"
author: "Yijia Lin, Bradley McKenzie and Diego Paroli"
date: "`r Sys.Date()`"
output: html_document
---

# Libraries

```{r, message=FALSE, warning=FALSE}
rm(list = ls())
library(tidyverse)
library(httr2)
library(igraph)
library(visNetwork)
library(tidygraph)
library(ggraph)
library(here)
library(caret)
```

# Get the data

```{r, message=FALSE, warning=FALSE}
nodes <- read_csv(here("network_data", "nodes.csv"))
links <- read_csv(here("network_data", "edges.csv"))
```

# Description of the dataset

This network is a directed and unweighted social communication network, which represents the exchange of emails among members of the Rovira i Virgili University in Spain, in 2003.

Source: [Netzschleuder](https://networks.skewed.de/net/uni_email).

### Properties

Directed, unweighted, social communication network.

### Nodes and links

```{r}
head(nodes)
head(links)
```

Within the `nodes` dataframe, the column `# index` is the one indicating the index of the nodes, the column `name` is the one indicating their corresponding name (although already anonymised), and the `_pos` column represents the coordinates of each node in a 2D space, typically used for visualization or layout in graph-related tasks. In the `links` dataframe, the column `# source` and `target` indicate the 2 nodes forming a link

### Graph:

```{r}
graph <- graph_from_data_frame(links, directed = TRUE, vertices = nodes)
graph
```

# Questions

## 1) Delete a fraction of real edges in the network and create a table of those links deleted (positive class) and of links non-present (negative class)

```{r}
# Set seed for reproducibility
set.seed(123)

# Randomly delete some real edges: set as positive class
edge_list <- as_data_frame(graph, what = "edges")
n_edges <- nrow(edge_list)
n_remove <- floor(0.1 * n_edges) #We will delete 10% of the real edges
removed_edges <- edge_list[sample(1:n_edges, n_remove), ]
graph_modified <- delete_edges(graph, E(graph)[from = removed_edges$from, to = removed_edges$to])

# Label the deleted real edges as positive class (1)
positive_edges <- removed_edges %>%
  mutate(label = 1)
```

```{r}
# Create a new data frame to register the negative class (made-up links)
false_edges <- data.frame()
# Filter the most connected nodes to create non-existent links 
#that are less obviously disconnected, which is better for machine learning
most_connected <- which(degree(graph)>5)
# Set seed again just in case
set.seed(123)

# Create a loop for creating made-up links, registering all in `false_edges`
while (nrow(false_edges) < n_remove) {
  node1 <- sample(most_connected, 1)
  node2 <- sample(most_connected, 1)
  
  # avoid self-connecting
  if (node1 == node2) next
  
  # Check if two nodes are connected, if not, create a negative link for them
  if (!are.connected(graph, node1, node2)) {
    edge_row <- data.frame(from = as_ids(V(graph)[node1]), 
                           to = as_ids(V(graph)[node2]),
                           label = 0)
    
    # avoid adding same links
    if (!any(apply(false_edges, 1, function(row) all(row == edge_row)))) {
      false_edges <- rbind(false_edges, edge_row)
    }
  }
}

```

```{r}
# Uniform the format of tables before binding
positive_edges <- positive_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

false_edges <- false_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

# Bind the positive and negative edges
all_edges <- bind_rows(positive_edges, false_edges)
head(all_edges)
table(all_edges$label)
```

## 2) Generate a number of proximity/similarty metrics heuristics for each link in the positive and negative class

```{r}
# Make sure the IDs are in numeric format, aligning with igraph
all_edges <- all_edges %>%
  mutate(from = as.numeric(from),
         to = as.numeric(to))
```

```{r}
# Create a function to compute different proximity/similarity metrics heuristics
# as additional features for later prediction models
compute_heuristics <- function(graph, edge_df) {
  edge_df <- edge_df %>%
    mutate(
      # Calculate common neighbors using the neighbors function
      common_neighbors = map2_int(from, to, ~ 
        length(intersect(neighbors(graph, .x, mode = "all"), 
                         neighbors(graph, .y, mode = "all")))),
      
      # Calculate Jaccard coefficient
      # We don't use the similarity.jaccard function as it's difficult to handle a matrix
      jaccard = map2_dbl(from, to, ~ {
        nei_x <- neighbors(graph, .x, mode = "all")
        nei_y <- neighbors(graph, .y, mode = "all")
        length(intersect(nei_x, nei_y)) / length(union(nei_x, nei_y))
      }),

      # Calculate Adamic-Adar metric
      # We don't use the similarity.invlogweighted function as it's difficult to handle a matrix
      adamic_adar = map2_dbl(from, to, ~ {
        nei_common <- intersect(neighbors(graph, .x, mode = "all"), 
                                neighbors(graph, .y, mode = "all"))
        if (length(nei_common) == 0) return(0)
        degrees <- degree(graph, nei_common, mode = "all")
        sum(1 / log(degrees))
      }),
      
      # Calculate preferential attachment by multiplay the degrees
      pref_attachment = map2_dbl(from, to, ~ 
        degree(graph, .x, mode = "all") * degree(graph, .y, mode = "all")),

      # Calculate the distances by using the distances function
      shortest_path = map2_dbl(from, to, ~ 
        distances(graph, v = .x, to = .y, mode = "all"))
    )
  return(edge_df)
}

```

```{r}
# Apply the created function and compute all proximity/similarity metrics heuristics
# that we learned in class
all_edges_with_heuristics <- compute_heuristics(graph, all_edges)
head(all_edges_with_heuristics)
```

## 3) Train a binary classifier to predict the links, i.e., to predict the class (positive/negative) using those heuristics. Use crossvalidation.

```{r}
# Create training (80%) and test set (20%)
set.seed(123)  # Set the seed for reproducibility
train_indices <- sample(1:nrow(all_edges_with_heuristics), size = 0.8 * nrow(all_edges_with_heuristics))
train_edges <- all_edges_with_heuristics[train_indices, ]
test_edges <- all_edges_with_heuristics[-train_indices, ]
```

```{r}
# Convert the labels into factors, for the logit model
train_edges$label <- as.factor(train_edges$label)
```


```{r}
# Build logit model using binomial family from glm to predict if a link exists (1) or not (0)
# Using different proximity/similarity metrics heuristics created previously as features in the glm
# Use cross validation to test the performance
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ common_neighbors + jaccard + adamic_adar + pref_attachment + shortest_path,
                  data = train_edges, method = "glm", family = binomial, trControl = train_control)
summary(model_cv)
```

We received a warning saying that "glm.fit algorithm did not converge", and the p value for all coefficients are close to 1, meaning that this model has very much room for improvement.

Firstly, we will check if there is the problem of multi-collinearity, and see if the number of positive and negative labels is balanced.

```{r}
cor(train_edges[, c("common_neighbors", "jaccard", "adamic_adar", "pref_attachment", "shortest_path")])
table(train_edges$label)
```

We can see that there are 861 negative labels and 883 positive labels, which is pretty balanced. However, we can see the correlation between `common_neighbors` and `adamic_adar` is extremely high (0.99), indicating redundancy. `common_neighbors` and `jaccard` are also strongly correlated (0.82), while `shortest_path` shows low correlation with others, suggesting it's more independent. We will try to drop highly correlated features (`common_neighbors`) to mitigate multicollinearity.

```{r}
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ jaccard + pref_attachment + shortest_path,
                  data = train_edges, method = "glm", family = binomial, trControl = train_control)
summary(model_cv)
```




## 4) Evaluate the precision of the model. Which heuristic is the most important. Why do you think it is the most important?

```{r}

```

## 5) Comment on potential ways to improve the link prediction

```{r}

```
