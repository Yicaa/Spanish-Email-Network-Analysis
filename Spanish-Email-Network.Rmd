---
title: "University Email Network"
author: "Yijia Lin, Bradley McKenzie and Diego Paroli"
date: "`r Sys.Date()`"
output: 
  rmdformats::html_clean:
    lightbox: false
    thumbnails: false
    toc: yes
    toc_float: true
    toc_depth: 3

---

```{r,include=F}
knitr::opts_chunk$set(cache=T,message=FALSE,warning=FALSE)
options(scipen=700)
```


## Libraries

```{r, message=FALSE, warning=FALSE}
rm(list = ls())
library(tidyverse)
library(igraph)
library(tidygraph)
library(ggraph)
library(ggthemes)
library(here)
library(caret)
```

## Read the data

```{r, message=FALSE, warning=FALSE}
nodes <- read_csv(here("network_data", "nodes.csv"))
links <- read_csv(here("network_data", "edges.csv"))
```

## Description of the dataset

This network is a directed and unweighted social communication network, which represents the exchange of emails among members of the Rovira i Virgili University in Spain, in 2003.

Source: [Netzschleuder](https://networks.skewed.de/net/uni_email).

#### Properties

Directed, unweighted, social communication network.

#### Nodes and links

```{r}
head(nodes)
head(links)
```

Within the `nodes` dataframe, the column `# index` is the one indicating the index of the nodes, the column `name` would contain the corresponding name of each node, but they have been anonymized for privacy reason so this column is still a series of numbers. The `_pos` column represents the coordinates of each node in a 2D space, used for visualization or layout in graph-related tasks. 

In the `links` dataframe, the column `# source` and `target` indicate the indexes of the 2 nodes forming a link.

#### Graph

```{r}
graph <- graph_from_data_frame(links, directed = TRUE, vertices = nodes)
graph
```

## Initial graph exploration

To understand the graph, we can plot the degree distribution to check whether we have the expected power-law distribution or another type. This will help to interpret the findings later when we remove links.

First, we check for any loops, these would be emails sent to self. And if so, we can simplify the graph to remove these (and also any eventual multiple edge). 

```{r}
paste0("The number of recursive (self-directed) emails in the network is: ", 
       ecount(graph) - ecount(simplify(graph)))

# we see that one exists, so we simplify the graph to remove it. 
graph <- simplify(graph)

# check our graph is setup properly
is_igraph(graph)
```

Next, calculate basic descriptive statistics of the plot:

```{r}
paste0("There are ", vcount(graph), " nodes and ", ecount(graph), " edges in our Spanish email network")

# check if our graph is fully connected
is_connected(graph)

#degree
degree_all <- degree(graph, mode="all")
degree_out <- degree(graph, mode="out")
paste0("The average degree is: ", round(mean(degree(graph)), 2), " when we DO NOT consider the direction of the emails.")
paste0("The average degree is: ", round(sum(degree_out)/vcount(graph), 2), " when we DO consider the emails to be directed outward from the node (sender) to a recipient")

# most connected node:
paste0("The most connected node is number ", which.max(degree(graph))[1], " which has ", max(degree(graph)), " links.")
```
For the purposes of this homework, we are not factoring in this directional property of the graph. We are considering that the emails are indicating a social relationship between the two nodes (sender and receiver) and it is irrelevant who sent the email. This means the average interactions for each individual node is 19.24 (which would represent email interactions with 19.24 different people on average)

Now check the degree distribution

```{r, fig.width=8}
# set average node for label 
avg_deg <- round(mean(degree(graph)),2)

# plot linear distribution
ggplot() + 
  geom_histogram(aes(x = degree_all), bins=40) + 
  geom_vline(aes(xintercept = avg_deg, colour = "red"), show.legend = FALSE) +
  annotate("text", x = avg_deg+5, y = 160, label = paste0("Avg deg = ", avg_deg), angle = 90, color = "red") + 
  labs(title = "Degree distribution histogram for Uni emails",
       x = "Degrees",
       y = "Number of nodes") +
  theme(axis.title.y = element_text(angle = 90))
```

We see the common power law distribution. There are few very connected nodes and many less connected nodes. We see that the max node must be node number 105 we reported earlier, with its 142 links. This is far more than the second most connected

Visualization of the network:

```{r, fig.width=8}
# plot the network overall, see if any large clusters emerge. 
# set colour and size only for the top 50 nodes
top_50_nodes <- order(degree_all, decreasing = TRUE)[1:50]
V(graph)$color <- "grey3"
V(graph)[top_50_nodes]$color <- "red"
V(graph)$size <- 0.75
V(graph)[top_50_nodes]$size <- 2

# plot the full network
ggraph(graph, layout = "kk") +
  geom_edge_link(width = 0.1, alpha = 0.5, color = "grey") +  
  geom_node_point(color = V(graph)$color, size = V(graph)$size) +  
  theme_void() +  
  ggtitle("Visualisation of the network, 50 most connected nodes highlighted")+
  theme(legend.position = "none")
```

We see that the most connected nodes are all centered in the graph. On the outside, we can see the nodes with only a couple of connections.


## Steps

### 1) Create table with positive and negative links 

#### Task 1: Delete a fraction of real edges in the network and create a table of those links deleted (positive class) and of links non-present (negative class)

First we'll create the positive class: existing edges that are removed from the network.

```{r}
# Set seed for reproducibility
set.seed(123)

# Randomly delete some real edges
edge_list <- as_data_frame(graph, what = "edges")
n_edges <- nrow(edge_list)
n_remove <- floor(0.1 * n_edges) # We will delete 10% of the real edges
removed_edges <- edge_list[sample(1:n_edges, n_remove), ]
# Formatting appropriately the edges to pass them as argument to delete_edges
edge_strings <- paste(removed_edges$from, 
                      removed_edges$to, 
                      sep = "|")
graph_modified <- delete_edges(graph, edges = edge_strings)

# Label the deleted real edges as positive class (1)
positive_edges <- removed_edges %>%
  mutate(label = 1)
```

We'll now focus on the negative class: edges that do not exist in the network.

We will be selecting false edges (non-existent links) only among high-degree nodes. This is done in order to select false edges that could at least be plausible and thus help us more in the training process. Low degree nodes would be unlikely to form an edge any way and so using those non-existent edges between low degree nodes would not add any information in our model.

```{r}
# Create a new data frame to register the negative class (non-existent links)
false_edges <- data.frame()

# Filter for more connected nodes
most_connected <- which(degree(graph)>15)
# We choose 15 arbitrarily (a number slightly below our average degree)

set.seed(123)

# Create a loop for creating made-up links, registering all in `false_edges`
while (nrow(false_edges) < n_remove) {
  node1 <- sample(most_connected, 1)
  node2 <- sample(most_connected, 1)
  
  # avoid self-connecting
  if (node1 == node2) next
  
  # Check if two nodes are connected, if not, create a negative link for them
  if (!are_adjacent(graph, node1, node2)) {
    edge_row <- data.frame(from = as_ids(V(graph)[node1]), 
                           to = as_ids(V(graph)[node2]),
                           label = 0)
    # Function to check to avoid adding same link
    if (!any(apply(false_edges, 1, function(row) all(row == edge_row)))) {
      false_edges <- rbind(false_edges, edge_row)
    }
  }
}
```

```{r}
# standardise the format of tables before binding
positive_edges <- positive_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

false_edges <- false_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

# Bind the positive and negative edges
all_edges <- bind_rows(positive_edges, false_edges)
head(all_edges)
table(all_edges$label)
```

### 2) Calculate heuristics for each class

#### Task 2: Generate a number of proximity/similarty metrics heuristics for each link in the positive and negative class

We'll create a function to compute different proximity/similarity metrics heuristics to be used as features in the prediction model later.

```{r}
compute_heuristics <- function(graph, edge_df) {
  edge_df <- edge_df %>%
    mutate(
      # Calculate common neighbors using the neighbors function
      common_neighbors = map2_int(from, to, ~ 
        length(intersect(neighbors(graph, .x, mode = "all"), 
                         neighbors(graph, .y, mode = "all")))),
      
      # Calculate Jaccard coefficient
      # We don't use the similarity.jaccard function as it's difficult to handle a matrix
      jaccard = map2_dbl(from, to, ~ {
        nei_x <- neighbors(graph, .x, mode = "all")
        nei_y <- neighbors(graph, .y, mode = "all")
        length(intersect(nei_x, nei_y)) / length(union(nei_x, nei_y))
      }),

      # Calculate Adamic-Adar metric
      # We don't use the similarity.invlogweighted function as it's difficult to handle a matrix
      adamic_adar = map2_dbl(from, to, ~ {
        nei_common <- intersect(neighbors(graph, .x, mode = "all"), 
                                neighbors(graph, .y, mode = "all"))
        if (length(nei_common) == 0) return(0)
        degrees <- degree(graph, nei_common, mode = "all")
        sum(1 / log(degrees))
      }),
      
      # Calculate preferential attachment by multiplying the degrees
      pref_attachment = map2_dbl(from, to, ~ 
        degree(graph, .x, mode = "all") * degree(graph, .y, mode = "all")),
    )
  return(edge_df)
}
```

We'll now apply the created function and compute all proximity/similarity metrics heuristics that we learned in class on our dataset.

```{r}
all_edges_with_heuristics <- compute_heuristics(graph, all_edges)
# view the true edges
head(all_edges_with_heuristics)
# view the fake edges
all_edges_with_heuristics |> filter(label == 0) |> head()
```

We see that the in the real edges, each model has heuristics > 0 where common neighbours exist. For the shortest path value, each are equal to 1 as the links are real so the shortest path is the direct connection.

With the fake edges, we see that as the selection is random, most do not have common neighbours, so their heuristic measures are mostly zero, but the shortest path is more useful here to observe how many degrees of separation they have. However, we cannot include shortest distance in the modelling because there is no variation in the true connections (all values = 1).

### 3) Predict the links using CV

####  Task 3: Train a binary classifier to predict the links, i.e., to predict the class (positive/negative) using those heuristics. Use crossvalidation.

First we split in test and training datasets:

```{r}
# Create training (80%) and test set (20%)
set.seed(123) 
train_indices <- sample(1:nrow(all_edges_with_heuristics), size = 0.8 * nrow(all_edges_with_heuristics))
train_edges <- all_edges_with_heuristics[train_indices, ]
test_edges <- all_edges_with_heuristics[-train_indices, ]

# Convert the labels into factors, for the logit model
train_edges$label <- as.factor(train_edges$label)
```

We'll now build a logit model (binomial family from `glm` package) to predict if a link exists (1) or not (0) using the different proximity/similarity metrics heuristics created previously as features in the model.

```{r}
# Use cross validation to test the performance
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ common_neighbors + jaccard + adamic_adar + pref_attachment,
                  data = train_edges, 
                  method = "glm", 
                  family = binomial, 
                  trControl = train_control,
                  metric = "Accuracy")
```

Finally we predict the test set. 

```{r}
# Predict the testing set
predictions <- predict(model_cv, newdata = test_edges, type = "prob")
# Probabilities of belonging to a class or the other
head(predictions)
```

### 4) Evaluate model performance

#### Step 4: Evaluate the precision of the model. Which heuristic is the most important. Why do you think it is the most important?

Let's first look at the summary of the model.

```{r}
summary(model_cv)
```

The most significant heuristic is Jaccard (in terms of lowest p-value), followed by Adamic-Adar ad then common neighbors. Preferential attachment is non significant. 

Looking at the magnitude of the coefficients could give us an hint on which of the heuristic is the most important. However, we must take into account that the heuristic measure do not use the same scale, so we will be running another model in which we standardize the features of the model

```{r}
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ common_neighbors + jaccard + adamic_adar + pref_attachment,
                  data = train_edges, 
                  method = "glm", family = binomial, 
                  trControl = train_control,
                  # apply standardization
                  preProcess = c("center", "scale"), 
                  metric = "Accuracy")
summary(model_cv)
```

Jaccard is still the most significant, however the heuristic with the biggest coefficient is Adamic-Adar. 

Adamic-Adar is a score that takes into account common neighbors of two nodes, but it also takes into account the degree of the common neighbors. This means that it gives more weight to common neighbors with lower degrees, which is interpreted as a good indicator of the likelihood of a link forming. On the opposite the Jaccard's coefficient does not do that, as it only calculates the proportion of neighbors in common, nor does it do it the common neighbors which simply counts the common neighbors. This particular feature of Adamic-Adar which discounts whether common neighbors have low or high degree is probably what makes it the most important heuristic in our model. 

Furthermore it is possible that given the power-law like degree distribution of our network this feature is potentially even more important. Many people are probably connected to the hubs of the network (which we can interpret as faculty or administrative people from the university), but if two people share connection with those hubs (ex. a professor that teaches many courses), it is not a good proxy that they are connected to each other. On the other hand if two people are connected to many common neighbors that are not hub (ex. students), it is likely that they might be in the same course and thus this is a good proxy that they are connected to each other.

Overall, we determine that Adamic-Adar is the most important heuristic because it weights less common relationships, which matches the real world experience we would see in a university sample.  

We'll now evaluate the model performance:

```{r}
# Confusion matrix
confusion_matrix <- confusionMatrix(as.factor(ifelse(predictions[, 2] > 0.5, 1, 0)), 
                                     as.factor(test_edges$label), positive = "1")
confusion_matrix
```

Overall accuracy is 78%, specificity is higher (89%), while sensitivity is lower (67%). This means, as can be seen from the confusion matrix, that the model is better at identifying negative links (those that never existed), than positive links (those that were actually present). The model often labels as non-existent link, links that actually were there.

### 5) Potential improvements 

#### Task 5: Comment on potential ways to improve the link prediction

**1. Accessing additional information**

The best way to improve model prediction is by including additional information on the students. This could be broken down into information on the nodes or edges. 

_Improved node information_ could include details on the type of university person they are. For example, are they a student or a professor or administrative staff. For students and professors, information on the faculty and subjects they take. Some sociodemographic information could help but it is less useful than university information. 

_Edge information_ could also improve prediction. For example, the number of emails sent between the individuals to indicate strength of the relationship. The number of emails could then be included as a weight in the edge when doing the prediction models. 
Temporal information would also be very helpful i.e. the time each email was sent. This would help to relate individuals who were at the university at the same time. this is useful because many students then could be enrolled in the same course but it could be 10-15 years apart so they would never actually cross over. 

One potential solution to improve the prediction with no information is to perform _unsupervised learning to generate clusters_ (aka communities for network analysis). With no targets, we can try to identify different neighbourhoods and assign values from the clustering. With the very basic information available, this is the only option to manually add on new columns of potentially identifiable data. The major limitation with this is that we wouldn't be able to understand why the clusters have formed and whether they are logical. 


**2. Try make more localised predictions**

Prediction is always difficult with class imbalance in a dataset. In this email network we do have quite extreme class imbalance overall. Oversampling of the true linkages is a basic way the prediction of positive cases could be improved. 

The model is trying to predict individual links. However, the average node has a degree of 19.24 links, while there are 1,133 nodes. That means only 1.7% of all possible edges exist. If the nodes were randomly assigned, that would mean there is a 1.70% chance that two nodes are connected together.

When we take random samples of the missing nodes, if you were trying to predict the entire graph, the predictive model would just predict 0 links. And it would have 98.3% accuracy because that is the majority class. This highlights why the So the important prediction variable for us is the true positive estimations. We don't see this in our predictions because we have taken a balanced sample of true and false links. However, one potential solution to this would be doing more localised predictions. Hypothetically, if we produced clusters/communities, and we treated each cluster as an ego graph, then made predictions within each of the clusters, the average degree relative to the number of nodes would increase and we would expect to see better predictive models locally. 


**3. Try further ML model optimisation with the heuristics**

A more complex model could include each of the heurisitcs weighted by their influence. This would likely be a smaller improvement, but optimising the heuristics and testing different combinations could optimise the model. The other options are using a prediction score using ensemble methods (e.g., averaging all significant heurisitcs into one composite score) or weighted linear models where coefficients reflect feature importance.
In a more basic change, the threshold for where a link is identified could be altered to find the optimal point on the ROC curve to find the best threshold. 


