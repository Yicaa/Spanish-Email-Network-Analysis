---
title: "University Email Network"
author: "Yijia Lin, Bradley McKenzie and Diego Paroli"
date: "`r Sys.Date()`"
output: 
  rmdformats::html_clean:
    lightbox: false
    thumbnails: false
---

```{r,include=F}
knitr::opts_chunk$set(cache=T,message=FALSE,warning=FALSE)
options(scipen=700)
```


## Libraries

```{r, message=FALSE, warning=FALSE}
rm(list = ls())
library(tidyverse)
library(igraph)
library(tidygraph)
library(ggraph)
library(ggthemes)
library(here)
library(caret)
```

## Read the data

```{r, message=FALSE, warning=FALSE}
nodes <- read_csv(here("network_data", "nodes.csv"))
links <- read_csv(here("network_data", "edges.csv"))
```

## Description of the dataset

This network is a directed and unweighted social communication network, which represents the exchange of emails among members of the Rovira i Virgili University in Spain, in 2003.

Source: [Netzschleuder](https://networks.skewed.de/net/uni_email).

#### Properties

Directed, unweighted, social communication network.

#### Nodes and links

```{r}
head(nodes)
head(links)
```

Within the `nodes` dataframe, the column `# index` is the one indicating the index of the nodes, the column `name` would contain the corresponding name of each node, but they have been anonymized for privacy reason so this column is still a series of numbers. The `_pos` column represents the coordinates of each node in a 2D space, used for visualization or layout in graph-related tasks. 

In the `links` dataframe, the column `# source` and `target` indicate the indexes of the 2 nodes forming a link.

#### Graph

```{r}
graph <- graph_from_data_frame(links, directed = TRUE, vertices = nodes)
graph
```

## Initial graph exploration

To understand the graph, we can plot the degree distribution to check whether we have the expected power-law distribution or another type. This will help to interpret the findings later when we remove links.

First, we check for any loops, these would be emails sent to self. And if so, we can simplify the graph to remove these (and also any eventual multiple edge). 

```{r}
paste0("The number of recursive (self-directed) emails in the network is: ", 
       ecount(graph) - ecount(simplify(graph)))

# we see that one exists, so we simplify the graph to remove it. 
graph <- simplify(graph)

# check our graph is setup properly
is_igraph(graph)
```

Next, calculate basic descriptive statistics of the plot:

```{r}
paste0("There are ", vcount(graph), " nodes and ", ecount(graph), " edges in our Spanish email network")

# check if our graph is fully connected
is_connected(graph)

#degree
degree_all <- degree(graph, mode="all")
degree_out <- degree(graph, mode="out")
paste0("The average degree is: ", round(mean(degree(graph)), 2), " when we DO NOT consider the direction of the emails.")
paste0("The average degree is: ", round(sum(degree_out)/vcount(graph), 2), " when we DO consider the emails to be directed outward from the node (sender) to a recipient")

# most connected node:
paste0("The most connected node is number ", which.max(degree(graph))[1], " which has ", max(degree(graph)), " links.")
```
For the purposes of this homework, we are not factoring in this directional property of the graph. We are considering that the emails are indicating a social relationship between the two nodes (sender and receiver) and it is irrelevant who sent the email. This means the average interactions for each individual node is 19.24 (which would represent email interactions with 19.24 different people on average)

Now check the degree distribution

```{r, fig.width=8}
# set average node for label 
avg_deg <- round(mean(degree(graph)),2)

# plot linear distribution
ggplot() + 
  geom_histogram(aes(x = degree_all), bins=40) + 
  geom_vline(aes(xintercept = avg_deg, colour = "red"), show.legend = FALSE) +
  annotate("text", x = avg_deg+5, y = 160, label = paste0("Avg deg = ", avg_deg), angle = 90, color = "red") + 
  labs(title = "Degree distribution histogram for Uni emails",
       x = "Degrees",
       y = "Number of nodes") +
  theme(axis.title.y = element_text(angle = 90))
```

We see the common power law distribution. There are few very connected nodes and many less connected nodes. We see that the max node must be node number 105 we reported earlier, with its 142 links. This is far more than the second most connected

Visualization of the network:

```{r, fig.width=8}
# plot the network overall, see if any large clusters emerge. Use the curved lines as it looks nice to represent emails. 
# set colour and size only for the top 50 nodes
top_50_nodes <- order(degree_all, decreasing = TRUE)[1:50]
V(graph)$color <- "grey3"
V(graph)[top_50_nodes]$color <- "red"
V(graph)$size <- 0.75
V(graph)[top_50_nodes]$size <- 2

# plot the full network
ggraph(graph, layout = "kk") +
  geom_edge_link(width = 0.1, alpha = 0.5, color = "grey") +  
  geom_node_point(color = V(graph)$color, size = V(graph)$size) +  
  theme_void() +  
  ggtitle("Visualisation of the network, 50 most connected nodes highlighted")+
  theme(legend.position = "none")
```

We see that the most connected nodes are all centered in the graph. On the outside, we can see the nodes with only a couple of connections.


## Steps

### 1) Delete a fraction of real edges in the network and create a table of those links deleted (positive class) and of links non-present (negative class)

First we'll create the positive class: existing edges that are removed from the network.

```{r}
# Set seed for reproducibility
set.seed(123)

# Randomly delete some real edges
edge_list <- as_data_frame(graph, what = "edges")
n_edges <- nrow(edge_list)
n_remove <- floor(0.1 * n_edges) # We will delete 10% of the real edges
removed_edges <- edge_list[sample(1:n_edges, n_remove), ]
# Formatting appropriately the edges to pass them as argument to delete_edges
edge_strings <- paste(removed_edges$from, removed_edges$to, sep = "|")
graph_modified <- delete_edges(graph, edges = edge_strings)

# Label the deleted real edges as positive class (1)
positive_edges <- removed_edges %>%
  mutate(label = 1)
```

We'll now focus on the negative class: edges that do not exist in the network.

We will be selecting false edges (non-existent links) only among high-degree nodes. This is done in order to select false edges that could at least be plausible and thus help us more in the training process. Low degree nodes would be unlikely to form an edge any way and so using those non-existent edges between low degree nodes would not add any information in our model.

```{r}
# Create a new data frame to register the negative class (non-existent links)
false_edges <- data.frame()

# Filter for more connected nodes
most_connected <- which(degree(graph)>15)
# We choose 15 arbitrarily (a number slightly below our average degree)

set.seed(123)

# Create a loop for creating made-up links, registering all in `false_edges`
while (nrow(false_edges) < n_remove) {
  node1 <- sample(most_connected, 1)
  node2 <- sample(most_connected, 1)
  
  # avoid self-connecting
  if (node1 == node2) next
  
  # Check if two nodes are connected, if not, create a negative link for them
  if (!are_adjacent(graph, node1, node2)) {
    edge_row <- data.frame(from = as_ids(V(graph)[node1]), 
                           to = as_ids(V(graph)[node2]),
                           label = 0)
    # Function to check to avoid adding same link
    if (!any(apply(false_edges, 1, function(row) all(row == edge_row)))) {
      false_edges <- rbind(false_edges, edge_row)
    }
  }
}
```

```{r}
# Uniform the format of tables before binding
positive_edges <- positive_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

false_edges <- false_edges %>%
  mutate(from = as.numeric(from), to = as.numeric(to))

# Bind the positive and negative edges
all_edges <- bind_rows(positive_edges, false_edges)
head(all_edges)
table(all_edges$label)
```

### 2) Generate a number of proximity/similarty metrics heuristics for each link in the positive and negative class

We'll create a function to compute different proximity/similarity metrics heuristics to be used as features in the prediction model later.

```{r}
compute_heuristics <- function(graph, edge_df) {
  edge_df <- edge_df %>%
    mutate(
      # Calculate common neighbors using the neighbors function
      common_neighbors = map2_int(from, to, ~ 
        length(intersect(neighbors(graph, .x, mode = "all"), 
                         neighbors(graph, .y, mode = "all")))),
      
      # Calculate Jaccard coefficient
      # We don't use the similarity.jaccard function as it's difficult to handle a matrix
      jaccard = map2_dbl(from, to, ~ {
        nei_x <- neighbors(graph, .x, mode = "all")
        nei_y <- neighbors(graph, .y, mode = "all")
        length(intersect(nei_x, nei_y)) / length(union(nei_x, nei_y))
      }),

      # Calculate Adamic-Adar metric
      # We don't use the similarity.invlogweighted function as it's difficult to handle a matrix
      adamic_adar = map2_dbl(from, to, ~ {
        nei_common <- intersect(neighbors(graph, .x, mode = "all"), 
                                neighbors(graph, .y, mode = "all"))
        if (length(nei_common) == 0) return(0)
        degrees <- degree(graph, nei_common, mode = "all")
        sum(1 / log(degrees))
      }),
      
      # Calculate preferential attachment by multiplying the degrees
      pref_attachment = map2_dbl(from, to, ~ 
        degree(graph, .x, mode = "all") * degree(graph, .y, mode = "all")),
    )
  return(edge_df)
}
```

We'll now apply the created function and compute all proximity/similarity metrics heuristics that we learned in class on our dataset.

```{r}
all_edges_with_heuristics <- compute_heuristics(graph, all_edges)
head(all_edges_with_heuristics)
```

### 3) Train a binary classifier to predict the links, i.e., to predict the class (positive/negative) using those heuristics. Use crossvalidation.

First we split in test and training datasets:

```{r}
# Create training (80%) and test set (20%)
set.seed(123) 
train_indices <- sample(1:nrow(all_edges_with_heuristics), size = 0.8 * nrow(all_edges_with_heuristics))
train_edges <- all_edges_with_heuristics[train_indices, ]
test_edges <- all_edges_with_heuristics[-train_indices, ]

# Convert the labels into factors, for the logit model
train_edges$label <- as.factor(train_edges$label)
```

We'll now build a logit model (binomial family from `glm` package) to predict if a link exists (1) or not (0) using the different proximity/similarity metrics heuristics created previously as features in the model.

```{r}
# Use cross validation to test the performance
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ common_neighbors + jaccard + adamic_adar + pref_attachment,
                  data = train_edges, 
                  method = "glm", family = binomial, 
                  trControl = train_control,
                  metric = "Accuracy")
```

Finally we predict the test set. 

```{r}
# Predict the testing set
predictions <- predict(model_cv, newdata = test_edges, type = "prob")
# Probabilities of belonging to a class or the other
head(predictions)
```


### 4) Evaluate the precision of the model. Which heuristic is the most important. Why do you think it is the most important?

Let's first look at the summary of the model.

```{r}
summary(model_cv)
```

The most significant heuristic is Jaccard, followed by Adamic-Adar ad then common neighbors. Preferential attachment is non significant. 

Looking at the magnitude of the coefficients could give us an hint on which of the heuristic is the most important. However, we must take into account that the heuristic measure do not use the same scale, so we will be running another model in which we standardize the features of the model

```{r}
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
model_cv <- train(label ~ common_neighbors + jaccard + adamic_adar + pref_attachment,
                  data = train_edges, 
                  method = "glm", family = binomial, 
                  trControl = train_control,
                  # apply standardization
                  preProcess = c("center", "scale"), 
                  metric = "Accuracy")
summary(model_cv)
```

Jaccard is still the most significant, however the heuristic with the biggest coefficient is Adamic-Adar. 

Adamic-Adar is a score that takes into account common neighbors of two nodes, but it also takes into account the degree of the common neighbors. This means that it gives more weight to common neighbors with lower degrees, which is interpreted as a good indicator of the likelihood of a link forming. On the opposite the Jaccard's coefficient does not do that, as it only calculates the proportion of neighbors in common, nor does it do it the common neighbors which simply counts the common neighbors. This particular feature of Adamic-Adar which discounts whether common neighbors have low or high degree is probably what makes it the most important heuristic in our model. Furthermore it is possible that given the power-law like degree distribution of our network this feature is potentially even more important. Many people are probably connected to the hubs of the network (which we can interpret as faculty or administrative people from the university), but if two people share connection with those hubs (ex. a professor that teaches many courses), it is not a good proxy that they are connected to each other. On the other hand if two people are connected to many common neighbors that are not hub (ex. students), it is likely that they might be in the same course and thus this is a good proxy that they are connected to each other.

We'll now evaluate the model performance:

```{r}
# Confusion matrix
confusion_matrix <- confusionMatrix(as.factor(ifelse(predictions[, 2] > 0.5, 1, 0)), 
                                     as.factor(test_edges$label), positive = "1")
confusion_matrix
```

Overall accuracy is 78%, specificity is higher (89%), while sensitivity is lower (67%). This means, as can be seen from the confusion matrix, that the model is better at identifying negative links (those that never existed), than positive links (those that were actually present). The model often labels as non-existent link, links that actually were there.

### 5) Comment on potential ways to improve the link prediction

**1. Accessing additional information**
		a. Being able to make the predictions based on information would improve the model greatly. For example, within the university, if we had information such as faculty and classes, we could greatly improve the predictive power in the model. However, because our model is 

Potential solution:

	• Without any of this information, unsupervised learning is the only option to generate new information. Using clustering is the only viable option to create more information to help improve the predictive models. 
		○ If we create a cluster variable and label each node with it's cluster, it could help improve the link prediction power. 
		○ This is a way to artificially create more information. The challenge is that we won't be able to know how the clusters have been identified within R. 

~~~ Should we try insert code to add clustering variables to improve prediction??
~~ I'm actually not sure right now how the heuristics work, and whether there is a way to actually read in additional information when making predictions

	**2. Overcoming the class imbalance problem**
Prediction is always difficult with class imbalance in a dataset. In this example we do have quite extreme class imbalance. 
The model is trying to predict individual links. However, the average node has 19.24 links, while there are 1,133 nodes. If the nodes were randomly assigned, that would mean there is a 1.70% chance that two nodes are connected together randomly. When we take random samples, the predictive model will nearly always go with the majority class, because it has a 98.3% chance of being correct. When we look at the number of true link predictions that each model made, we see it is very small. 
If the model predicts no link for all observations, it would be correct 98.3% of the time which is good odds. So the important prediction variable for us is the true positive estimations. 
Taking the samples is a very good way to try balance the data. But the chances of a true link are so low in a power-law network with an average degree this low. 
Solution: Again, additional information would probably critical. To try and improve the predictions, creating smaller neighbourhoods and ego graphs, then making predictions in smaller related graphs is the best option. Within these graphs, the average degree relative to the number of nodes would increase and we would see higher predictive models. 
~~~ IF we want to test this, could do a sample neighbourhood that is centred around a certain cluster or a well connected node. 

